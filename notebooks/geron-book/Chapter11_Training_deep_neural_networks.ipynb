{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from utils import show_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the mathematical theory of artificial neural networks, the universal approximation theorem states that a feed-forward network with a single hidden layer containing a finite number of neurons can approximate continuous functions on compact subsets of $\\mathbb{R}^n$, under mild assumptions on the activation function.\n",
    "\n",
    "Therefore, in theory there is no need to use more than one layer when we could just increase the number of units of the single hidden layer. In practice, for complex tasks, a MLP can achieve the same accuracy with a much faster training. However, multi-layer architectures introduce a few new issues during training which have to been handled and will be discussed in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/exploding gradients problems\n",
    "[Xavier and Yoshua (2010)](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf): \"We can see that the variance of the gradient on the weights is the same for all layers, but the variance of the backpropagated gradient might still vanish or explode as we consider deeper networks. Note how this is reminiscent\n",
    "of issues raised when studying recurrent neural networks (Bengio et al., 1994), which can be seen as very deep\n",
    "networks when unfolded through time.\"\n",
    "\n",
    "In the following subsection we will describe a few tricks to improve the stability of the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He intitialisation\n",
    "Xavier and Yoshua (2010) and [Kaiming He et al (2015)](https://arxiv.org/pdf/1502.01852v1.pdf) give us weights initialisation techniques which provide a more stable variance of gradients and backpropagated gradient. If we denote with $n_{\\text{input}}$ and $n_{\\text{output}}$ the number of input and output connection respectively, then:\n",
    "\\begin{equation}\n",
    "\\text{Activation: Sigmoid}; W \\sim U(-r, +r) \\Longrightarrow r = \\sqrt{\\frac{6}{n_{\\text{input}} + n_\\text{output}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Activation: Hyperbolic tangent}; W \\sim U(-r, +r) \\Longrightarrow r = 4\\sqrt{\\frac{6}{n_{\\text{input}} + n_\\text{output}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Activation: ReLU}; W \\sim U(-r, +r) \\Longrightarrow r = \\sqrt{2}\\sqrt{\\frac{6}{n_{\\text{input}} + n_\\text{output}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Activation: Sigmoid}; W \\sim U(-r, +r) \\Longrightarrow \\sigma = \\sqrt{\\frac{2}{n_{\\text{input}} + n_\\text{output}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Activation: Hyperbolic tangent}; W \\sim U(-r, +r) \\Longrightarrow \\sigma = 4\\sqrt{\\frac{2}{n_{\\text{input}} + n_\\text{output}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Activation: ReLU}; W \\sim U(-r, +r) \\Longrightarrow \\sigma = \\sqrt{2}\\sqrt{\\frac{2}{n_{\\text{input}} + n_\\text{output}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer(\n",
    "    factor=2.0,\n",
    "    mode='FAN_IN',\n",
    "    uniform=False,\n",
    "    seed=None,\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "#tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_initializer=he_init, name='hidden1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating activation functions\n",
    "Sigmoid $\\sigma(z)$ as activation function has the following issues:\n",
    "- Gradient approaches to zero as |z| >> 0.\n",
    "- Not centered around zero (see issues in Xavier and Yoshua (2010)).\n",
    "- Non-linear everywhere, so not very fast to be computed.\n",
    "\n",
    "Considerations with ReLU(z):\n",
    "- Very wise to be computed because it's piecewise linear.\n",
    "- Dying hidden units: If a hidden unit starts outputting zeros, there is no way to bring the unit back to live with a null gradient. You might find out that more then half of your hidden units die during training.\n",
    "\n",
    "Extensions of ReLU(z):\n",
    "- LeakyReLU(z) = $max(az, z)$: hidden units never die. $a$ is generally set to 0.01. Note that when $a$=1, your architecture becomes a plain logistic regression. Source: [Bing Xu et al. (2015)](https://arxiv.org/pdf/1505.00853.pdf)\n",
    "- RandomizedLeakyReLU(z) = $max(az, z)$ where $a$ if randomly sampled during training and kept fixed during testing (similarly to dropout). It seems to perform well and acts as regulariser.\n",
    "- ParametricLeakyRelu(z) = $max(az, z)$ where $a$ is treated like a parameter instead of a hyper-parameter, so $a$ is optimised by backpropagation. This increases the flexibility of your function, so there is a higher risk of overfitting.\n",
    "- ExponentialLU(z) = $a(e^z - 1)$ if $z < 0$ else $z$. Source: [Clevert et al. (2016)](https://arxiv.org/pdf/1511.07289v5.pdf).\n",
    "    - Considerations:\n",
    "        - Slower than LReLU to be computed.\n",
    "        - Average of the function tends to be closer to zero.\n",
    "        - Smooth everywhere. Gradient does not jumps around zero.\n",
    "        - Non-zero gradient for $z<0$, so hidden units don't die.\n",
    "\n",
    "\n",
    "As a rule of thumb: ELU > LeakyReLU and variants > tanh > logistic. You can also try RReLU if you are underfitting or PReLU if overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalisation\n",
    "Batch normalisation is another tool in your arsenal to help with vanishing/exploding gradients.\n",
    "[Sergey Ioffe (2015)](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "\n",
    "\n",
    "How it works:\n",
    "\n",
    "This technique consists of adding an operation in the model just before the activation function of each layer, simply zero-centering and normalizing the inputs, then scaling the and shifting the result using two new parameters (\\gamma, \\beta) per layer. In other words, this operation lets the model learn the optimal scale and mean (\\gamma, \\beta) of each input for each layer.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu_B = \\frac{1}{m_B} \\sum_{i=1}^{m_B} \\mathbf{x} ^ {(i)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_B^2 = \\frac{1}{m_B} \\sum_{i=1}^{m_B} \\ (\\mathbf{x} ^ {(i)} - \\mu_B) ^ 2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{x}} ^ {(i)} = \\frac{\\mathbf{x} ^ {(i)} - \\mu_B} {\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{z}} ^ {(i)} = \\gamma \\hat{\\mathbf{x}} ^ {(i)} + \\beta\n",
    "\\end{equation}\n",
    "- At test time, empirical mean and standard deviation are taken from the whole training set.\n",
    "\n",
    "Advantages:\n",
    "- Vanishing/exploding gradients are strongly reduced, at the point that we can use tanh and even logistic.\n",
    "- Network is much less sensitive to weight initialisation. However, weight initialisation is done offline so IMO this is not really a big advantage. However, this is still a good property.\n",
    "- Training can require one order of magnitude less training steps.\n",
    "- Batch normalisation acts as a regulariser, similarly to dropout.\n",
    "\n",
    "Disadvantages:\n",
    "- There is more logic involved with your network, more error-prone during the implementation.\n",
    "- Slower predictions.\n",
    "\n",
    "Generally batch normalization is great and make a lot of intuitive sense. The fact that it acts as a regularizer is great for datasets with low signal-to-noise ratio. It's also cool that it does not introduce and hyper-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST and split in training, validation and test set.\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Sizes of the dataset.\n",
    "train_size, pixels_rows, pixels_cols = X_train.shape\n",
    "test_size, _, _ = X_test.shape\n",
    "nr_features = pixels_rows * pixels_cols\n",
    "nr_labels = len(np.unique(y_train))\n",
    "\n",
    "# split X_train in smaller X_train and X_valid.\n",
    "split_threshold = int(train_size * 0.7)  \n",
    "X_test = X_test.reshape(test_size, pixels_rows * pixels_cols) / 255.\n",
    "X_train = X_train.reshape(train_size, pixels_rows * pixels_cols) / 255.\n",
    "X_train, X_valid = X_train[:split_threshold], X_train[split_threshold:]\n",
    "y_train, y_valid = y_train[:split_threshold], y_train[split_threshold:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't specify any activation function for the fully connected layers because we want to apply the activation function after each batch normalization layer. However, many researchers argue that it is just as good, or even better, to place the batch normalization layers after (rather than before) the activation.\n",
    "\n",
    "In my view, I tend to prefer applying batch normalization AFTER the activation so the gradient will be computed over normalized and unbiased quantities (a non-linear activation will shift the mean away from zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, nr_features), name='X')\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None), name='y')\n",
    "\n",
    "training = tf.placeholder_with_default(input=False, shape=(), name='is_test')\n",
    "with tf.name_scope('nn-architecture'):\n",
    "    hidden_1 = tf.layers.dense(inputs=X, units=300, activation=None, name='hidden_layer_1')\n",
    "    batch_norm_1 = tf.layers.batch_normalization(inputs=hidden_1, axis=-1, momentum=0.9, epsilon=0.001, name='batch_norm_1')\n",
    "    hidden_2 = tf.layers.dense(inputs=tf.nn.elu(batch_norm_1), units=100, activation=None, name='hidden_layer_2')\n",
    "    batch_norm_2 = tf.layers.batch_normalization(inputs=hidden_2, axis=-1, momentum=0.9, epsilon=0.001, name='batch_norm_2')\n",
    "    output = tf.layers.dense(inputs=tf.nn.elu(batch_norm_2), units=nr_labels, activation=None, name='output_layer')\n",
    "    logits = tf.layers.batch_normalization(inputs=output, axis=-1, momentum=0.9, epsilon=0.001, name='logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=logits,\n",
    "        name='cross_entropy',\n",
    "    )\n",
    "    cross_entropy_loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('gradient_descent'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01, name='gradient_descent')\n",
    "\n",
    "    # You could equivalently use training_op = optimizer.minimize(cross_entropy).\n",
    "    gradients = optimizer.compute_gradients(cross_entropy)\n",
    "    training_op = optimizer.apply_gradients(grads_and_vars=gradients, name='apply_gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('validation'):\n",
    "    is_correct_label_int = tf.nn.in_top_k(\n",
    "        predictions=logits,\n",
    "        targets=y,\n",
    "        k=1,\n",
    "        name='is_correct_label_vec',\n",
    "    )\n",
    "    is_correct_label_float = tf.cast(is_correct_label_int, tf.float32)\n",
    "    accuracy = tf.reduce_mean(is_correct_label_float, name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6614886194747605&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;is_test/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_BOOL\\n        tensor_shape {\\n        }\\n        bool_val: false\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;is_test&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;is_test/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden_layer_1/kernel&quot;\\n  input: &quot;hidden_layer_1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden_layer_1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden_layer_1/bias&quot;\\n  input: &quot;hidden_layer_1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden_layer_1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/hidden_layer_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden_layer_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/hidden_layer_1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;nn-architecture/hidden_layer_1/MatMul&quot;\\n  input: &quot;hidden_layer_1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_1/gamma&quot;\\n  input: &quot;batch_norm_1/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_1/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_1/beta&quot;\\n  input: &quot;batch_norm_1/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_1/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_1/moving_mean&quot;\\n  input: &quot;batch_norm_1/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_1/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_1/moving_variance&quot;\\n  input: &quot;batch_norm_1/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_1/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_1/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;batch_norm_1/moving_variance/read&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/Rsqrt&quot;\\n  input: &quot;batch_norm_1/gamma/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/hidden_layer_1/BiasAdd&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;batch_norm_1/moving_mean/read&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;batch_norm_1/beta/read&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_1/batchnorm/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul_1&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/Elu&quot;\\n  op: &quot;Elu&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden_layer_2/kernel&quot;\\n  input: &quot;hidden_layer_2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden_layer_2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden_layer_2/bias&quot;\\n  input: &quot;hidden_layer_2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_layer_2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden_layer_2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/hidden_layer_2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;nn-architecture/Elu&quot;\\n  input: &quot;hidden_layer_2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/hidden_layer_2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;nn-architecture/hidden_layer_2/MatMul&quot;\\n  input: &quot;hidden_layer_2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_2/gamma&quot;\\n  input: &quot;batch_norm_2/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_2/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_2/beta&quot;\\n  input: &quot;batch_norm_2/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_2/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_2/moving_mean&quot;\\n  input: &quot;batch_norm_2/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_2/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;batch_norm_2/moving_variance&quot;\\n  input: &quot;batch_norm_2/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;batch_norm_2/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;batch_norm_2/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;batch_norm_2/moving_variance/read&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/Rsqrt&quot;\\n  input: &quot;batch_norm_2/gamma/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/hidden_layer_2/BiasAdd&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;batch_norm_2/moving_mean/read&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;batch_norm_2/beta/read&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/batch_norm_2/batchnorm/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul_1&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/Elu_1&quot;\\n  op: &quot;Elu&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output_layer/kernel&quot;\\n  input: &quot;output_layer/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output_layer/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output_layer/bias&quot;\\n  input: &quot;output_layer/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_layer/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output_layer/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/output_layer/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;nn-architecture/Elu_1&quot;\\n  input: &quot;output_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/output_layer/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;nn-architecture/output_layer/MatMul&quot;\\n  input: &quot;output_layer/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/gamma/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/gamma&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/gamma/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logits/gamma&quot;\\n  input: &quot;logits/gamma/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/gamma/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logits/gamma&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/gamma&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/beta/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logits/beta&quot;\\n  input: &quot;logits/beta/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logits/beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_mean/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_mean&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_mean/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logits/moving_mean&quot;\\n  input: &quot;logits/moving_mean/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_mean&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_mean/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logits/moving_mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_mean&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_variance/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_variance&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_variance/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logits/moving_variance&quot;\\n  input: &quot;logits/moving_variance/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_variance&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/moving_variance/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logits/moving_variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/moving_variance&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;logits/moving_variance/read&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/Rsqrt&quot;\\n  input: &quot;logits/gamma/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/output_layer/BiasAdd&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logits/moving_mean/read&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;logits/beta/read&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;nn-architecture/logits/batchnorm/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul_1&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cross_entropy/cross_entropy/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cross_entropy/cross_entropy/cross_entropy&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/add_1&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cross_entropy/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cross_entropy/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;cross_entropy/cross_entropy/cross_entropy&quot;\\n  input: &quot;cross_entropy/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;cross_entropy/cross_entropy/cross_entropy&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradient_descent/gradients/Shape&quot;\\n  input: &quot;gradient_descent/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;cross_entropy/cross_entropy/cross_entropy:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;cross_entropy/cross_entropy/cross_entropy:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradient_descent/gradients/Fill&quot;\\n  input: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/ExpandDims&quot;\\n  input: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Shape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/cross_entropy/cross_entropy/cross_entropy_grad/mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Sum_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nn-architecture/output_layer/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Shape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/output_layer/BiasAdd&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Mul_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/Neg&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logits/moving_mean/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;output_layer/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;nn-architecture/Elu_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/AddN&quot;\\n  input: &quot;logits/gamma/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/AddN&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/Elu_1_grad/EluGrad&quot;\\n  op: &quot;EluGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;nn-architecture/Elu_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Shape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/Elu_1_grad/EluGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/Elu_1_grad/EluGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Sum_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nn-architecture/hidden_layer_2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Shape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/hidden_layer_2/BiasAdd&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Mul_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/Neg&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;batch_norm_2/moving_mean/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden_layer_2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;nn-architecture/Elu&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/AddN_1&quot;\\n  input: &quot;batch_norm_2/gamma/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/AddN_1&quot;\\n  input: &quot;nn-architecture/batch_norm_2/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/Elu_grad/EluGrad&quot;\\n  op: &quot;EluGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;nn-architecture/Elu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 300\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Shape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/Elu_grad/EluGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/Elu_grad/EluGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Sum_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;nn-architecture/hidden_layer_1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 300\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Shape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;nn-architecture/hidden_layer_1/BiasAdd&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Mul_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Sum_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/Neg&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;batch_norm_1/moving_mean/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden_layer_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/AddN_2&quot;\\n  input: &quot;batch_norm_1/gamma/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradient_descent/gradients/AddN_2&quot;\\n  input: &quot;nn-architecture/batch_norm_1/batchnorm/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul_1&quot;\\n  input: &quot;^gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_hidden_layer_1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden_layer_1/kernel&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_hidden_layer_1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden_layer_1/bias&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_batch_norm_1/gamma/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;batch_norm_1/gamma&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_batch_norm_1/beta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;batch_norm_1/beta&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_1/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_1/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_hidden_layer_2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden_layer_2/kernel&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_hidden_layer_2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden_layer_2/bias&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/hidden_layer_2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden_layer_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_batch_norm_2/gamma/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;batch_norm_2/gamma&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_batch_norm_2/beta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;batch_norm_2/beta&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/batch_norm_2/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@batch_norm_2/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_output_layer/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;output_layer/kernel&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_output_layer/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;output_layer/bias&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/output_layer/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_logits/gamma/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;logits/gamma&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/gamma&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient/update_logits/beta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;logits/beta&quot;\\n  input: &quot;gradient_descent/apply_gradient/learning_rate&quot;\\n  input: &quot;gradient_descent/gradients/nn-architecture/logits/batchnorm/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradient_descent/apply_gradient&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_batch_norm_1/beta/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_batch_norm_1/gamma/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_batch_norm_2/beta/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_batch_norm_2/gamma/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_hidden_layer_1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_hidden_layer_1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_hidden_layer_2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_hidden_layer_2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_logits/beta/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_logits/gamma/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_output_layer/bias/ApplyGradientDescent&quot;\\n  input: &quot;^gradient_descent/apply_gradient/update_output_layer/kernel/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;validation/is_correct_label_vec/is_correct_label_vec/k&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;validation/is_correct_label_vec/is_correct_label_vec&quot;\\n  op: &quot;InTopKV2&quot;\\n  input: &quot;nn-architecture/logits/batchnorm/add_1&quot;\\n  input: &quot;y&quot;\\n  input: &quot;validation/is_correct_label_vec/is_correct_label_vec/k&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;validation/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;validation/is_correct_label_vec/is_correct_label_vec&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;validation/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;validation/accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;validation/Cast&quot;\\n  input: &quot;validation/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6614886194747605&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution phase\n",
    "When using batch normalization, there are two differences during the execution phase.\n",
    "- Training placeholder has to be set to true-\n",
    "- Get the list of operations to run mean and standard deviation of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "batch_iters = len(X_train) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 1; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 2; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 3; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 4; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 5; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 6; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 7; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 8; Training accuracy: 0.0; Validation accuracy: 0.0.\n",
      "Epoch: 9; Training accuracy: 0.0; Validation accuracy: 0.0.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# Construction phase. Save summary statistics for Tensorboard.\n",
    "dir_log = 'tf_logs/run_{}/'.format(datetime.utcnow().strftime('%Y%m%d_%H%M%S'))\n",
    "summary_accuracy_train = tf.summary.scalar('Accuracy_train', accuracy)\n",
    "summary_accuracy_valid = tf.summary.scalar('Accuracy_valid', accuracy)\n",
    "file_writer = tf.summary.FileWriter(dir_log, graph=tf.get_default_graph())\n",
    "\n",
    "\n",
    "extra_update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS, scope=None)\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_iter in range(batch_iters):\n",
    "            batch_idx_start = batch_iter * batch_size\n",
    "            batch_idx_end = (1 + batch_iter) * batch_size\n",
    "            X_batch = X_train[batch_idx_start:batch_idx_end]\n",
    "            y_batch = y_train[batch_idx_start:batch_idx_end]\n",
    "            session.run([training_op, extra_update_ops], feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_train = session.run(accuracy, feed_dict={X: X_train, y: y_train})\n",
    "        accuracy_valid = session.run(accuracy, feed_dict={X: X_valid, y: y_valid})\n",
    "        print('Epoch: {}; Training accuracy: {}; Validation accuracy: {}.'.format(epoch, accuracy_train, accuracy_valid))\n",
    "        \n",
    "        # Save model\n",
    "        path_model = os.path.join('tf_checkpoints', 'session.ckpt')\n",
    "        saver.save(session, path_model)\n",
    "        \n",
    "        # Save summary stats.\n",
    "        file_writer.add_summary(\n",
    "            summary=session.run(summary_accuracy_train, feed_dict={X: X_train, y: y_train}),\n",
    "            global_step=epoch,\n",
    "        )\n",
    "        file_writer.add_summary(\n",
    "            summary=session.run(summary_accuracy_valid, feed_dict={X: X_valid, y: y_valid}),\n",
    "            global_step=epoch,\n",
    "        )\n",
    "        # Flush. See: https://github.com/tensorflow/tensorflow/issues/2353#issuecomment-287516024\n",
    "        file_writer.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Why is accuracy always zero_ Find the bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing pre-trained layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding overfitting through regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-hands-on-ml",
   "language": "python",
   "name": "book-hands-on-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
